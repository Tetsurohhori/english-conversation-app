import streamlit as st
import os
import time
from time import sleep
from pathlib import Path
from streamlit.components.v1 import html
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain.schema import SystemMessage
from openai import OpenAI
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import functions as ft
import constants as ct


# å„ç¨®è¨­å®š
load_dotenv()
st.set_page_config(
    page_title=ct.APP_NAME
)

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.markdown(f"## {ct.APP_NAME}")

# åˆæœŸå‡¦ç†
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.start_flg = False
    st.session_state.pause_flg = False  # ä¸€æ™‚ä¸­æ–­ãƒ•ãƒ©ã‚°
    st.session_state.pre_mode = ""
    st.session_state.shadowing_flg = False
    st.session_state.shadowing_button_flg = False
    st.session_state.shadowing_count = 0
    st.session_state.shadowing_first_flg = True
    st.session_state.shadowing_audio_input_flg = False
    st.session_state.shadowing_evaluation_first_flg = True
    st.session_state.dictation_flg = False
    st.session_state.dictation_button_flg = False
    st.session_state.dictation_count = 0
    st.session_state.dictation_first_flg = True
    st.session_state.dictation_chat_message = ""
    st.session_state.dictation_evaluation_first_flg = True
    st.session_state.chat_open_flg = False
    st.session_state.problem = ""
    
    st.session_state.openai_obj = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
    st.session_state.llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)
    st.session_state.memory = ConversationSummaryBufferMemory(
        llm=st.session_state.llm,
        max_token_limit=1000,
        return_messages=True
    )

    # è‹±èªãƒ¬ãƒ™ãƒ«åˆ¥ã®Chainã¯å‹•çš„ã«ä½œæˆï¼ˆåˆæœŸåŒ–æ™‚ã«ã¯ä½œæˆã—ãªã„ï¼‰
    st.session_state.chain_basic_conversation = None

# æœ€ä¸Šéƒ¨ã®è¨­å®šã‚¨ãƒªã‚¢ï¼ˆå†ç”Ÿé€Ÿåº¦ãƒ»ãƒ¢ãƒ¼ãƒ‰ãƒ»è‹±èªãƒ¬ãƒ™ãƒ«ï¼‰
col1, col2, col3 = st.columns([1, 1, 1])
with col1:
    st.session_state.speed = st.selectbox(label="å†ç”Ÿé€Ÿåº¦", options=ct.PLAY_SPEED_OPTION, index=3)
with col2:
    st.session_state.mode = st.selectbox(label="ãƒ¢ãƒ¼ãƒ‰", options=[ct.MODE_1, ct.MODE_2, ct.MODE_3])
    # ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ãŸéš›ã®å‡¦ç†
    if st.session_state.mode != st.session_state.pre_mode:
        # è‡ªå‹•ã§ãã®ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
        st.session_state.start_flg = False
        # ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        if st.session_state.mode == ct.MODE_1:
            st.session_state.dictation_flg = False
            st.session_state.shadowing_flg = False
        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.shadowing_count = 0
        if st.session_state.mode == ct.MODE_2:
            st.session_state.dictation_flg = False
        # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸æŠæ™‚ã®åˆæœŸåŒ–å‡¦ç†
        st.session_state.dictation_count = 0
        if st.session_state.mode == ct.MODE_3:
            st.session_state.shadowing_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã‚’éè¡¨ç¤ºã«ã™ã‚‹
        st.session_state.chat_open_flg = False
    st.session_state.pre_mode = st.session_state.mode
with col3:
    st.session_state.englv = st.selectbox(label="è‹±èªãƒ¬ãƒ™ãƒ«", options=ct.ENGLISH_LEVEL_OPTION)

# ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã®é¸æŠï¼ˆã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ãƒ»ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
if st.session_state.mode in [ct.MODE_2, ct.MODE_3]:
    col5, col6 = st.columns(2)
    with col5:
        st.session_state.topic = st.selectbox(
            label="ãƒ†ãƒ¼ãƒ",
            options=list(ct.TOPIC_OPTIONS.keys()),
            key="topic_select"
        )
    with col6:
        st.session_state.situation = st.selectbox(
            label="å ´é¢",
            options=list(ct.SITUATION_OPTIONS.keys()),
            key="situation_select"
        )

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å­¦ç¿’çµ±è¨ˆã‚’è¡¨ç¤º
with st.sidebar:
    st.markdown("## ğŸ“Š å­¦ç¿’çµ±è¨ˆ")
    
    if 'score_history' in st.session_state and len(st.session_state.score_history) > 0:
        scores = [item['score'] for item in st.session_state.score_history]
        
        # çµ±è¨ˆæƒ…å ±
        st.metric("ç·å­¦ç¿’å›æ•°", len(scores))
        st.metric("å¹³å‡ã‚¹ã‚³ã‚¢", f"{sum(scores) / len(scores):.1f}ç‚¹")
        st.metric("æœ€é«˜ã‚¹ã‚³ã‚¢", f"{max(scores)}ç‚¹")
        st.metric("æœ€æ–°ã‚¹ã‚³ã‚¢", f"{scores[-1]}ç‚¹")
        
        # ã‚¹ã‚³ã‚¢ã®æ¨ç§»ã‚°ãƒ©ãƒ•
        st.markdown("### ã‚¹ã‚³ã‚¢æ¨ç§»")
        import pandas as pd
        df_scores = pd.DataFrame({
            'å›æ•°': range(1, len(scores) + 1),
            'ã‚¹ã‚³ã‚¢': scores
        })
        st.line_chart(df_scores.set_index('å›æ•°'))
        
        # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®çµ±è¨ˆ
        st.markdown("### ãƒ¢ãƒ¼ãƒ‰åˆ¥çµ±è¨ˆ")
        mode_stats = {}
        for item in st.session_state.score_history:
            mode = item['mode']
            if mode not in mode_stats:
                mode_stats[mode] = []
            mode_stats[mode].append(item['score'])
        
        for mode, mode_scores in mode_stats.items():
            st.markdown(f"**{mode}**: å¹³å‡ {sum(mode_scores) / len(mode_scores):.1f}ç‚¹ ({len(mode_scores)}å›)")
        
        # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
        if st.button("ğŸ“ å­¦ç¿’å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ"):
            st.session_state.score_history = []
            st.rerun()
    else:
        st.info("ã¾ã å­¦ç¿’è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\nç·´ç¿’ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ï¼")
    
    st.divider()
    st.markdown("## â„¹ï¸ æ“ä½œèª¬æ˜")
    st.markdown("""
    - ãƒ¢ãƒ¼ãƒ‰ã¨è‹±èªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠ
    - ã€Œé–‹å§‹ã€ãƒœã‚¿ãƒ³ã§ç·´ç¿’é–‹å§‹
    - éŸ³å£°å…¥åŠ›ã¯ã€Œç™ºè©±é–‹å§‹ã€â†’è©±ã™â†’ã€Œç™ºè©±çµ‚äº†ã€
    - 5ç§’æ²ˆé»™ã§è‡ªå‹•ç¢ºå®š
    - ã€Œä¸€æ™‚ä¸­æ–­ã€ã§ã„ã¤ã§ã‚‚ä¸­æ–­å¯èƒ½
    """)

with st.chat_message("assistant", avatar="images/ai_icon.jpg"):
    st.markdown("ã“ã¡ã‚‰ã¯ç”ŸæˆAIã«ã‚ˆã‚‹éŸ³å£°è‹±ä¼šè©±ã®ç·´ç¿’ã‚¢ãƒ—ãƒªã§ã™ã€‚ä½•åº¦ã‚‚ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã€è‹±èªåŠ›ã‚’ã‚¢ãƒƒãƒ—ã•ã›ã¾ã—ã‚‡ã†ã€‚")
    st.markdown("**ã€æ“ä½œèª¬æ˜ã€‘**")
    st.success("""
    - ãƒ¢ãƒ¼ãƒ‰ã¨è‹±èªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠã—ã€ã€Œé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ç·´ç¿’ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ã€‚
    - ãƒ¢ãƒ¼ãƒ‰ã¯ã€Œæ—¥å¸¸è‹±ä¼šè©±ã€ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‹ã‚‰é¸ã¹ã¾ã™ã€‚
    - éŸ³å£°å…¥åŠ›ï¼šã€Œç™ºè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã—ã€ã€Œç™ºè©±çµ‚äº†ã€ãƒœã‚¿ãƒ³ã§ç¢ºå®šã—ã¾ã™ï¼ˆ5ç§’æ²ˆé»™ã§è‡ªå‹•ç¢ºå®šï¼‰ã€‚
    - ã€Œä¸€æ™‚ä¸­æ–­ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã“ã¨ã§ã€ã„ã¤ã§ã‚‚ç·´ç¿’ã‚’ä¸­æ–­ã§ãã¾ã™ã€‚
    """)

# é–‹å§‹ãƒ»ä¸€æ™‚ä¸­æ–­ãƒœã‚¿ãƒ³ï¼ˆ5:5é…ç½®ï¼‰
col_btn1, col_btn2 = st.columns([5, 5])
with col_btn1:
    if st.session_state.start_flg:
        # é–‹å§‹çŠ¶æ…‹ã§ã¯ã€Œé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–
        st.button("é–‹å§‹", use_container_width=True, type="primary", disabled=True)
    else:
        st.session_state.start_flg = st.button("é–‹å§‹", use_container_width=True, type="primary")
with col_btn2:
    # ä¸€æ™‚ä¸­æ–­ãƒœã‚¿ãƒ³ï¼ˆé–‹å§‹çŠ¶æ…‹ã®æ™‚ã®ã¿æœ‰åŠ¹ï¼‰
    if st.session_state.start_flg:
        if st.button("ä¸€æ™‚ä¸­æ–­", use_container_width=True, type="secondary"):
            # ä¸­æ–­å‡¦ç†: çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.start_flg = False
            st.session_state.shadowing_flg = False
            st.session_state.dictation_flg = False
            st.session_state.chat_open_flg = False
            st.info("âœ‹ ä¸€æ™‚ä¸­æ–­ã—ã¾ã—ãŸã€‚ã€Œé–‹å§‹ã€ãƒœã‚¿ãƒ³ã§å†é–‹ã§ãã¾ã™ã€‚")
            st.rerun()
    else:
        st.button("ä¸€æ™‚ä¸­æ–­", use_container_width=True, type="secondary", disabled=True)

st.divider()

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä¸€è¦§è¡¨ç¤º
for message in st.session_state.messages:
    if message["role"] == "assistant":
        with st.chat_message(message["role"], avatar="images/ai_icon.jpg"):
            st.markdown(message["content"])
    elif message["role"] == "user":
        with st.chat_message(message["role"], avatar="images/user_icon.jpg"):
            st.markdown(message["content"])
    else:
        st.divider()

# LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¸‹éƒ¨ã«ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã®ãƒœã‚¿ãƒ³è¡¨ç¤º
if st.session_state.shadowing_flg:
    st.session_state.shadowing_button_flg = st.button("ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°é–‹å§‹")
if st.session_state.dictation_flg:
    st.session_state.dictation_button_flg = st.button("ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")

# ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ¢ãƒ¼ãƒ‰ã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å—ä»˜æ™‚ã«å®Ÿè¡Œ
if st.session_state.chat_open_flg:
    st.info("AIãŒèª­ã¿ä¸Šã’ãŸéŸ³å£°ã‚’ã€ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰ãã®ã¾ã¾å…¥åŠ›ãƒ»é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")

st.session_state.dictation_chat_message = st.chat_input("â€»ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€é¸æŠæ™‚ä»¥å¤–ã¯é€ä¿¡ä¸å¯")

if st.session_state.dictation_chat_message and not st.session_state.chat_open_flg:
    st.stop()

# ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
if st.session_state.start_flg:

    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€
    # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ãƒãƒ£ãƒƒãƒˆé€ä¿¡æ™‚
    if st.session_state.mode == ct.MODE_3 and (st.session_state.dictation_button_flg or st.session_state.dictation_count == 0 or st.session_state.dictation_chat_message):
        if st.session_state.dictation_first_flg:
            # è‹±èªãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå•é¡Œæ–‡ç”ŸæˆChainã‚’ä½œæˆï¼ˆãƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è€ƒæ…®ï¼‰
            base_prompt = ct.SYSTEM_TEMPLATE_CREATE_PROBLEM[st.session_state.englv]
            topic = st.session_state.get('topic', 'ãƒ©ãƒ³ãƒ€ãƒ ')
            situation = st.session_state.get('situation', 'æŒ‡å®šãªã—')
            modified_prompt = ft.create_problem_prompt_with_context(base_prompt, topic, situation)
            st.session_state.chain_create_problem = ft.create_chain(modified_prompt)
            st.session_state.dictation_first_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ä»¥å¤–
        if not st.session_state.chat_open_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()

            st.session_state.chat_open_flg = True
            st.session_state.dictation_flg = False
            st.rerun()
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ™‚ã®å‡¦ç†
        else:
            # ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰å…¥åŠ›ã•ã‚ŒãŸå ´åˆã«ã®ã¿è©•ä¾¡å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            if not st.session_state.dictation_chat_message:
                st.stop()
            
            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(st.session_state.problem)
            with st.chat_message("user", avatar=ct.USER_ICON_PATH):
                st.markdown(st.session_state.dictation_chat_message)

            # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
            st.session_state.messages.append({"role": "user", "content": st.session_state.dictation_chat_message})
            
            with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=st.session_state.dictation_chat_message
                )
                st.session_state.chain_evaluation = ft.create_chain(system_template)
                # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                llm_response_evaluation = ft.create_evaluation()
            
            # ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºã—ã¦ãƒãƒƒã‚¸è¡¨ç¤º
            score = ft.extract_score(llm_response_evaluation)
            if score is not None:
                ft.display_score_badge(score)
                # ã‚¹ã‚³ã‚¢ã‚’å±¥æ­´ã«è¨˜éŒ²
                if 'score_history' not in st.session_state:
                    st.session_state.score_history = []
                st.session_state.score_history.append({
                    'mode': ct.MODE_3,
                    'score': score,
                    'timestamp': time.time()
                })
            
            # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(llm_response_evaluation)
            st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
            st.session_state.messages.append({"role": "other"})
            
            # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
            st.session_state.dictation_flg = True
            st.session_state.dictation_chat_message = ""
            st.session_state.dictation_count += 1
            st.session_state.chat_open_flg = False

            st.rerun()

    
    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œæ—¥å¸¸è‹±ä¼šè©±ã€
    if st.session_state.mode == ct.MODE_1:
        # è‹±èªãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸChainã‚’å‹•çš„ã«ä½œæˆï¼ˆãƒ¬ãƒ™ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã«å¯¾å¿œï¼‰
        if st.session_state.chain_basic_conversation is None or not hasattr(st.session_state, 'current_level') or st.session_state.current_level != st.session_state.englv:
            st.session_state.chain_basic_conversation = ft.create_chain(ct.SYSTEM_TEMPLATE_BASIC_CONVERSATION[st.session_state.englv])
            st.session_state.current_level = st.session_state.englv
        
        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        ft.record_audio(audio_input_file_path)

        # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            transcript = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text

        # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)

        with st.spinner("å›ç­”ã®éŸ³å£°èª­ã¿ä¸Šã’æº–å‚™ä¸­..."):
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—
                llm_response = st.session_state.chain_basic_conversation.predict(input=audio_input_text)
                
                # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
                llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                    model="tts-1",
                    voice="alloy",
                    input=llm_response
                )

                # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
                audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
                ft.save_to_wav(llm_response_audio.content, audio_output_file_path)
            except Exception as e:
                st.error(f"âš ï¸ å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.stop()

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        ft.play_wav(audio_output_file_path, speed=st.session_state.speed)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": audio_input_text})
        st.session_state.messages.append({"role": "assistant", "content": llm_response})


    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€
    # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚
    if st.session_state.mode == ct.MODE_2 and (st.session_state.shadowing_button_flg or st.session_state.shadowing_count == 0 or st.session_state.shadowing_audio_input_flg):
        if st.session_state.shadowing_first_flg:
            # è‹±èªãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå•é¡Œæ–‡ç”ŸæˆChainã‚’ä½œæˆï¼ˆãƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è€ƒæ…®ï¼‰
            base_prompt = ct.SYSTEM_TEMPLATE_CREATE_PROBLEM[st.session_state.englv]
            topic = st.session_state.get('topic', 'ãƒ©ãƒ³ãƒ€ãƒ ')
            situation = st.session_state.get('situation', 'æŒ‡å®šãªã—')
            modified_prompt = ft.create_problem_prompt_with_context(base_prompt, topic, situation)
            st.session_state.chain_create_problem = ft.create_chain(modified_prompt)
            st.session_state.shadowing_first_flg = False
        
        if not st.session_state.shadowing_audio_input_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()

        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        st.session_state.shadowing_audio_input_flg = True
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        ft.record_audio(audio_input_file_path)
        st.session_state.shadowing_audio_input_flg = False

        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            transcript = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(st.session_state.problem)
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)
        
        # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨éŸ³å£°å…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
        st.session_state.messages.append({"role": "user", "content": audio_input_text})

        with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
            if st.session_state.shadowing_evaluation_first_flg:
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=audio_input_text
                )
                st.session_state.chain_evaluation = ft.create_chain(system_template)
                st.session_state.shadowing_evaluation_first_flg = False
            # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
            llm_response_evaluation = ft.create_evaluation()
        
        # ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºã—ã¦ãƒãƒƒã‚¸è¡¨ç¤º
        score = ft.extract_score(llm_response_evaluation)
        if score is not None:
            ft.display_score_badge(score)
            # ã‚¹ã‚³ã‚¢ã‚’å±¥æ­´ã«è¨˜éŒ²
            if 'score_history' not in st.session_state:
                st.session_state.score_history = []
            st.session_state.score_history.append({
                'mode': ct.MODE_2,
                'score': score,
                'timestamp': time.time()
            })
        
        # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response_evaluation)
        st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
        st.session_state.messages.append({"role": "other"})
        
        # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
        st.session_state.shadowing_flg = True
        st.session_state.shadowing_count += 1

        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«å†æç”»
        st.rerun()