import streamlit as st
import os
import time
from pathlib import Path
from pydub import AudioSegment
from audio_recorder_streamlit import audio_recorder
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain.schema import SystemMessage
from langchain.memory import ConversationSummaryBufferMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
import constants as ct
from openai import OpenAIError, APIError, APIConnectionError, RateLimitError

def record_audio(audio_input_file_path):
    """
    éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒéŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦éŒ²éŸ³ã‚’é–‹å§‹ãƒ»åœæ­¢ã—ã¾ã™
    """
    
    # éŒ²éŸ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆsession_stateã§ç®¡ç†ï¼‰
    if 'audio_recording_counter' not in st.session_state:
        st.session_state.audio_recording_counter = 0
    
    # å‰å›ã®éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
    if 'previous_audio_bytes' not in st.session_state:
        st.session_state.previous_audio_bytes = None
    
    st.info("ğŸ¤ ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³ã‚’é–‹å§‹ã—ã€è©±ã—çµ‚ã‚ã£ãŸã‚‰ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦åœæ­¢ã—ã¦ãã ã•ã„")
    st.warning("âš ï¸ æœ€ä½ã§ã‚‚1ç§’ä»¥ä¸Šè©±ã—ã¦ãã ã•ã„ï¼ˆçŸ­ã™ãã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ï¼‰")
    
    # éŒ²éŸ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’keyã«ä½¿ç”¨
    audio_bytes = audio_recorder(
        text="",
        recording_color="#e74c3c",
        neutral_color="#3498db",
        icon_name="microphone",
        icon_size="3x",
        key=f"audio_recorder_{st.session_state.audio_recording_counter}"
    )

    # æ–°ã—ã„éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼ˆå‰å›ã¨ç•°ãªã‚‹å ´åˆï¼‰
    if audio_bytes and audio_bytes != st.session_state.previous_audio_bytes:
        # å‰å›ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        st.session_state.previous_audio_bytes = audio_bytes
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
        audio_length = len(audio_bytes)
        
        # éŸ³å£°ãŒçŸ­ã™ãã‚‹å ´åˆï¼ˆãƒã‚¤ãƒˆæ•°ã§åˆ¤å®šï¼‰
        # wavå½¢å¼ã®å ´åˆã€44ãƒã‚¤ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ + å®Ÿãƒ‡ãƒ¼ã‚¿
        # æœ€ä½ã§ã‚‚1ç§’åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ï¼ˆ16kHzã€16bitã€ãƒ¢ãƒãƒ©ãƒ« = ç´„32KBï¼‰
        min_size = 10000  # ç´„0.3ç§’åˆ†ï¼ˆå®‰å…¨ãƒãƒ¼ã‚¸ãƒ³å«ã‚€ï¼‰
        
        if audio_length < min_size:
            st.error("âŒ éŒ²éŸ³ãŒçŸ­ã™ãã¾ã™ã€‚ã‚‚ã†ä¸€åº¦éŒ²éŸ³ã—ã¦ãã ã•ã„ï¼ˆæœ€ä½1ç§’ä»¥ä¸Šè©±ã—ã¦ãã ã•ã„ï¼‰")
            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã—ã¦ãƒªã‚»ãƒƒãƒˆ
            st.session_state.audio_recording_counter += 1
            st.session_state.previous_audio_bytes = None
            time.sleep(2)  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹æ™‚é–“ã‚’ç¢ºä¿
            st.rerun()
            return False
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        try:
            with open(audio_input_file_path, 'wb') as audio_file:
                audio_file.write(audio_bytes)
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’ç¢ºèªï¼ˆpydubã‚’ä½¿ç”¨ï¼‰
            from pydub import AudioSegment
            audio = AudioSegment.from_file(audio_input_file_path)
            duration_seconds = len(audio) / 1000.0  # ãƒŸãƒªç§’ã‚’ç§’ã«å¤‰æ›
            
            if duration_seconds < 0.5:
                st.error(f"âŒ éŒ²éŸ³ãŒçŸ­ã™ãã¾ã™ï¼ˆ{duration_seconds:.1f}ç§’ï¼‰ã€‚ã‚‚ã†ä¸€åº¦éŒ²éŸ³ã—ã¦ãã ã•ã„ï¼ˆæœ€ä½1ç§’ä»¥ä¸Šï¼‰")
                os.remove(audio_input_file_path)  # çŸ­ã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                st.session_state.audio_recording_counter += 1
                st.session_state.previous_audio_bytes = None
                time.sleep(2)
                st.rerun()
                return False
            
            st.success(f"âœ… éŒ²éŸ³å®Œäº†ï¼ï¼ˆ{duration_seconds:.1f}ç§’ï¼‰éŸ³å£°ã‚’å‡¦ç†ä¸­...")
            
            # æ¬¡å›ã®ãŸã‚ã«éŒ²éŸ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
            st.session_state.audio_recording_counter += 1
            st.session_state.previous_audio_bytes = None
            return True
            
        except Exception as e:
            st.error(f"âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.session_state.audio_recording_counter += 1
            st.session_state.previous_audio_bytes = None
            time.sleep(2)
            st.rerun()
            return False
    
    # éŒ²éŸ³ãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯å‡¦ç†ã‚’ä¸­æ–­
    st.stop()
    return False

def transcribe_audio(audio_input_file_path):
    """
    éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    Args:
        audio_input_file_path: éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    try:
        with open(audio_input_file_path, 'rb') as audio_input_file:
            transcript = st.session_state.openai_obj.audio.transcriptions.create(
                model="whisper-1",
                file=audio_input_file,
                language="en"
            )
        
        # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        os.remove(audio_input_file_path)
        
        return transcript
        
    except RateLimitError:
        st.error("âš ï¸ APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        st.stop()
    except APIConnectionError:
        st.error("âš ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except APIError as e:
        st.error(f"âš ï¸ OpenAI APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.stop()
    except Exception as e:
        st.error(f"âš ï¸ éŸ³å£°èªè­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists(audio_input_file_path):
            os.remove(audio_input_file_path)
        st.stop()

def save_to_wav(llm_response_audio, audio_output_file_path):
    """
    ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
    Args:
        llm_response_audio: LLMã‹ã‚‰ã®å›ç­”ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        audio_output_file_path: å‡ºåŠ›å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """

    temp_audio_output_filename = f"{ct.AUDIO_OUTPUT_DIR}/temp_audio_output_{int(time.time())}.mp3"
    with open(temp_audio_output_filename, "wb") as temp_audio_output_file:
        temp_audio_output_file.write(llm_response_audio)
    
    audio_mp3 = AudioSegment.from_file(temp_audio_output_filename, format="mp3")
    audio_mp3.export(audio_output_file_path, format="wav")

    # éŸ³å£°å‡ºåŠ›ç”¨ã«ä¸€æ™‚çš„ã«ä½œã£ãŸmp3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    os.remove(temp_audio_output_filename)

def play_wav(audio_output_file_path, speed=1.0):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’ï¼ˆStreamlitã®st.audioã‚’ä½¿ç”¨ï¼‰
    Args:
        audio_output_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        speed: å†ç”Ÿé€Ÿåº¦ï¼ˆ1.0ãŒé€šå¸¸é€Ÿåº¦ã€0.5ã§åŠåˆ†ã®é€Ÿã•ã€2.0ã§å€é€Ÿãªã©ï¼‰
    """
    try:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        audio = AudioSegment.from_wav(audio_output_file_path)
        
        # éŸ³å£°ã®é•·ã•ã‚’å–å¾—ï¼ˆãƒŸãƒªç§’ï¼‰
        audio_duration = len(audio) / 1000.0  # ç§’ã«å¤‰æ›
        
        # é€Ÿåº¦ã‚’å¤‰æ›´
        if speed != 1.0:
            # frame_rateã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§é€Ÿåº¦ã‚’èª¿æ•´
            modified_audio = audio._spawn(
                audio.raw_data, 
                overrides={"frame_rate": int(audio.frame_rate * speed)}
            )
            # å…ƒã®frame_rateã«æˆ»ã™ã“ã¨ã§æ­£å¸¸å†ç”Ÿã•ã›ã‚‹ï¼ˆãƒ”ãƒƒãƒã‚’ä¿æŒã—ãŸã¾ã¾é€Ÿåº¦ã ã‘å¤‰æ›´ï¼‰
            modified_audio = modified_audio.set_frame_rate(audio.frame_rate)
            modified_audio.export(audio_output_file_path, format="wav")
            # é€Ÿåº¦å¤‰æ›´å¾Œã®éŸ³å£°ã‚’å†èª­ã¿è¾¼ã¿
            audio = AudioSegment.from_wav(audio_output_file_path)
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        with open(audio_output_file_path, 'rb') as audio_file:
            audio_bytes = audio_file.read()
        
        # Streamlitã®audioæ©Ÿèƒ½ã§å†ç”Ÿ
        st.audio(audio_bytes, format='audio/wav')
        
        # HTML5ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¿ã‚°ã‚’ä½¿ç”¨ã—ã¦è‡ªå‹•å†ç”Ÿã‚’è©¦ã¿ã‚‹
        import base64
        audio_base64 = base64.b64encode(audio_bytes).decode()
        audio_html = f"""
        <audio autoplay>
            <source src="data:audio/wav;base64,{audio_base64}" type="audio/wav">
        </audio>
        """
        st.markdown(audio_html, unsafe_allow_html=True)
        
        # éŸ³å£°ã®é•·ã•åˆ†ã ã‘å¾…ã¤ï¼ˆå†ç”ŸãŒå®Œäº†ã™ã‚‹ã¾ã§ï¼‰
        # +1ç§’ã®ä½™è£•ã‚’æŒãŸã›ã‚‹
        time.sleep(audio_duration + 1.0)
        
    except Exception as e:
        st.error(f"âš ï¸ éŸ³å£°å†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    finally:
        # éŸ³å£°å†ç”Ÿå®Œäº†å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists(audio_output_file_path):
            os.remove(audio_output_file_path)

def create_chain(system_template):
    """
    LLMã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆç”¨ã®Chainä½œæˆ
    """

    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_template),
        MessagesPlaceholder(variable_name="history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    chain = ConversationChain(
        llm=st.session_state.llm,
        memory=st.session_state.memory,
        prompt=prompt
    )

    return chain

def create_problem_prompt_with_context(base_prompt, topic, situation):
    """
    ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è€ƒæ…®ã—ãŸå•é¡Œæ–‡ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    Args:
        base_prompt: åŸºæœ¬ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        topic: é¸æŠã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯
        situation: é¸æŠã•ã‚ŒãŸã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
    """
    additional_context = ""
    
    if topic and topic != "ãƒ©ãƒ³ãƒ€ãƒ ":
        topic_desc = ct.TOPIC_OPTIONS.get(topic, "")
        if topic_desc:
            additional_context += f"\n    Focus on: {topic_desc}"
    
    if situation and situation != "æŒ‡å®šãªã—":
        situation_desc = ct.SITUATION_OPTIONS.get(situation, "")
        if situation_desc:
            additional_context += f"\n    Situation: {situation_desc}"
    
    # åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿è¾¼ã‚€
    if additional_context:
        modified_prompt = base_prompt.rstrip() + additional_context + "\n"
        return modified_prompt
    
    return base_prompt

def create_problem_and_play_audio():
    """
    å•é¡Œç”Ÿæˆã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆå†ç”Ÿã¯å‘¼ã³å‡ºã—å´ã§è¡Œã†ï¼‰
    Args:
        chain: å•é¡Œæ–‡ç”Ÿæˆç”¨ã®Chain
        speed: å†ç”Ÿé€Ÿåº¦ï¼ˆ1.0ãŒé€šå¸¸é€Ÿåº¦ã€0.5ã§åŠåˆ†ã®é€Ÿã•ã€2.0ã§å€é€Ÿãªã©ï¼‰
        openai_obj: OpenAIã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    Returns:
        tuple: (problem, llm_response_audio, audio_output_file_path)
    """
    try:
        # å•é¡Œæ–‡ã‚’ç”Ÿæˆã™ã‚‹Chainã‚’å®Ÿè¡Œã—ã€å•é¡Œæ–‡ã‚’å–å¾—
        problem = st.session_state.chain_create_problem.predict(input="")

        # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
        llm_response_audio = st.session_state.openai_obj.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input=problem
        )

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
        save_to_wav(llm_response_audio.content, audio_output_file_path)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚‚è¿”ã™ï¼ˆå†ç”Ÿã¯å‘¼ã³å‡ºã—å´ã§è¡Œã†ï¼‰
        return problem, llm_response_audio, audio_output_file_path
        
    except RateLimitError:
        st.error("âš ï¸ APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        st.stop()
    except APIConnectionError:
        st.error("âš ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except APIError as e:
        st.error(f"âš ï¸ OpenAI APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.stop()
    except Exception as e:
        st.error(f"âš ï¸ å•é¡Œæ–‡ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.stop()

def create_evaluation():
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã®è©•ä¾¡ç”Ÿæˆ
    """
    try:
        llm_response_evaluation = st.session_state.chain_evaluation.predict(input="")
        return llm_response_evaluation
        
    except RateLimitError:
        st.error("âš ï¸ APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        st.stop()
    except APIConnectionError:
        st.error("âš ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except APIError as e:
        st.error(f"âš ï¸ OpenAI APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.stop()
    except Exception as e:
        st.error(f"âš ï¸ è©•ä¾¡ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.stop()

def extract_score(evaluation_text):
    """
    è©•ä¾¡ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
    Args:
        evaluation_text: è©•ä¾¡çµæœã®ãƒ†ã‚­ã‚¹ãƒˆ
    Returns:
        score: ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰ã€æŠ½å‡ºã§ããªã„å ´åˆã¯None
    """
    import re
    
    # ã‚¹ã‚³ã‚¢ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆä¾‹: "ã‚¹ã‚³ã‚¢: 85/100ç‚¹"ï¼‰
    score_pattern = r'ã‚¹ã‚³ã‚¢[:ï¼š]\s*(\d+)/100ç‚¹'
    match = re.search(score_pattern, evaluation_text)
    
    if match:
        return int(match.group(1))
    return None

def display_score_badge(score):
    """
    ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸãƒãƒƒã‚¸ã‚’è¡¨ç¤º
    Args:
        score: ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
    """
    if score is None:
        return
    
    if score >= 90:
        st.success(f"ğŸ‰ ç´ æ™´ã‚‰ã—ã„ï¼ ã‚¹ã‚³ã‚¢: {score}/100ç‚¹")
    elif score >= 70:
        st.info(f"ğŸ‘ è‰¯ãã§ãã¾ã—ãŸï¼ ã‚¹ã‚³ã‚¢: {score}/100ç‚¹")
    elif score >= 50:
        st.warning(f"ğŸ“ ã‚‚ã†å°‘ã—ï¼ ã‚¹ã‚³ã‚¢: {score}/100ç‚¹")
    else:
        st.error(f"ğŸ’ª é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼ ã‚¹ã‚³ã‚¢: {score}/100ç‚¹")